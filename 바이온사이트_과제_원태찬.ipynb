{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244166ae",
   "metadata": {},
   "source": [
    "## csv파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d37320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      inchikey  \\\n",
      "0  FNHKPVJBJVTLMP-UHFFFAOYSA-N   \n",
      "1  CUDVHEFYRIWYQD-UHFFFAOYSA-N   \n",
      "2  TTZSNFLLYPYKIL-UHFFFAOYSA-N   \n",
      "3  UOVCGJXDGOGOCZ-UHFFFAOYSA-N   \n",
      "4  CUIHSIWYWATEQL-UHFFFAOYSA-N   \n",
      "\n",
      "                                              smiles  group activity  \n",
      "0  CNC(=O)c1cc(Oc2ccc(NC(=O)Nc3ccc(Cl)c(C(F)(F)F)...  train   active  \n",
      "1  CNC(=O)c1cccc2cc(Oc3ccnc4cc(OCC5(N)CC5)c(OC)cc...  train   active  \n",
      "2  Cc1cc2cc(Oc3ccnc(Nc4cccc(CS(=O)(=O)NCCN(C)C)c4...   test   active  \n",
      "3       COc1cc2c(cc1F)C(c1ccccc1Cl)=Nc1c(n[nH]c1C)N2  train   active  \n",
      "4  Cc1ccc(Nc2nccc(N(C)c3ccc4c(C)n(C)nc4c3)n2)cc1S...   test   active  \n",
      "5530\n",
      "5530\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('C:/Users/user/Desktop/cmpd.csv')\n",
    "print(df.head())\n",
    "print(len(df))\n",
    "\n",
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f2f0c",
   "metadata": {},
   "source": [
    "## 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e80f58e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PHXJVRSECIGDHY-UHFFFAOYSA-N    4\n",
       "PIQCTGMSNWUMAF-UHFFFAOYSA-N    3\n",
       "CUDVHEFYRIWYQD-UHFFFAOYSA-N    3\n",
       "DXCUKNQANPLTEJ-UHFFFAOYSA-N    3\n",
       "WOSKHXYHFSIKNG-UHFFFAOYSA-N    3\n",
       "                              ..\n",
       "DTWGYWUIWVOFBV-UHFFFAOYSA-N    1\n",
       "GLDPXWNDIUPOHH-UHFFFAOYSA-N    1\n",
       "SNNUMARRAFQOGY-UHFFFAOYSA-N    1\n",
       "KRYZCYZIWKIKGN-UHFFFAOYSA-N    1\n",
       "CZXAZXLPPWLLGJ-UHFFFAOYSA-N    1\n",
       "Name: inchikey, Length: 5489, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inchikey'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a70340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNC(=O)c1cccc2cc(Oc3ccnc4cc(OCC5(N)CC5)c(OC)cc34)ccc12                       3\n",
       "COc1cc2nccc(Oc3ccc(NC(=O)NC4CC4)c(Cl)c3)c2cc1C(N)=O                          3\n",
       "COc1cc(OC)cc(N(CCNC(C)C)c2ccc3ncc(-c4cnn(C)c4)nc3c2)c1                       2\n",
       "Cc1ccc(Nc2nccc(N(C)c3ccc4c(C)n(C)nc4c3)n2)cc1S(N)(=O)=O                      2\n",
       "CCN(CC)CCOc1ccc(Nc2ncc3cc(-c4c(Cl)cccc4Cl)c(=O)n(C)c3n2)cc1                  2\n",
       "                                                                            ..\n",
       "Cc1cnc(NC(=O)Nc2cc(Br)c(C)cc2OC[C@@H]2CNCCO2)cn1                             1\n",
       "Fc1ccc2c(-c3nc4cc(N5CCC(N6CCCCC6)CC5)ccc4[nH]3)[nH]nc2c1                     1\n",
       "CNC(=O)n1ccc2cc(Oc3ccnc(NC(=O)c4ccc(C5CN(CC(C)(C)O)C5)cc4)c3)c(OCCOC)cc21    1\n",
       "CCCCC(=O)Nc1cc(-c2c[nH]c3ncccc23)cc(Cl)n1                                    1\n",
       "O=C1Nc2ncccc2/C1=C/c1ccc(N2CCOCC2)cc1                                        1\n",
       "Name: smiles, Length: 5507, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smiles'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14772fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active          2704\n",
       "inactive        1886\n",
       "unknown          599\n",
       "intermediate     341\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669d45b",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3182e4",
   "metadata": {},
   "source": [
    "### unknown삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e79dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inchikey    False\n",
      "smiles      False\n",
      "group       False\n",
      "activity    False\n",
      "dtype: bool\n",
      "\n",
      "inchikey    False\n",
      "smiles      False\n",
      "group       False\n",
      "activity    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "active          2704\n",
       "inactive        1886\n",
       "intermediate     341\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN 값 확인\n",
    "print(df.isna().any())\n",
    "print(f'\\n{df.isnull().any()}\\n\\n\\n')\n",
    "\n",
    "# unknown 삭제\n",
    "df = df[df['activity'] != 'unknown'].copy()\n",
    "df['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab381f",
   "metadata": {},
   "source": [
    "### active는 1 나머지는 0(이진분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "387f5338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 문자열이 포함된 열을 숫자형으로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "df['inchikey'] = label_encoder.fit_transform(df['inchikey'])\n",
    "df['smiles'] = label_encoder.fit_transform(df['smiles'])\n",
    "\n",
    "# active는 1 나머지는 0\n",
    "df['activity'] = df['activity'].map({'active':'1', 'inactive':'0', 'intermediate':'0'})\n",
    "df['activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5b29e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df['group'] == 'train']\n",
    "print(len(df_train))\n",
    "df_test = df[df['group'] == 'test']\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8562674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3491, 2) (1440, 2) (3491,) (1440,)\n"
     ]
    }
   ],
   "source": [
    "array_train = df_train.values\n",
    "x_train = array_train[:, 0:2]\n",
    "y_train = array_train[:, 3]\n",
    "\n",
    "array_test = df_test.values\n",
    "x_test = array_test[:, 0:2]\n",
    "y_test = array_test[:, 3]\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b9223",
   "metadata": {},
   "source": [
    "## feature 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0e7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# feature 표준화\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7849c5",
   "metadata": {},
   "source": [
    "## feature 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33c6345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# feature 정규화\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(x_train)  \n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(x_test)  \n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3910a",
   "metadata": {},
   "source": [
    "## 랜덤포레스트(채택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "440c7a56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 :  ['0' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "실제값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "Randomforest acc :  0.6076388888888888\n",
      "Randomforest acc :  0.6076388888888888\n",
      "[0.59979737 0.5811359  0.68458418 0.71906694 0.56186613]\n",
      "0.629\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# model(entropy가 gini보다 많이 쳐줌)\n",
    "model = RandomForestClassifier(criterion='entropy', n_estimators = 1001, random_state = 12) # n_estimators = 1001은 의사결정나무 갯수가 1001개\n",
    "fit_model = model.fit(x_train, y_train)\n",
    "pred = fit_model.predict(x_test)\n",
    "print('예측값 : ', pred[:10])\n",
    "print('실제값 : ', np.array(y_test[:10]))\n",
    "\n",
    "# 분류 정확도\n",
    "print('Randomforest acc : ', sum(y_test == pred) / len(y_test)) # 0.6076388888888888\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Randomforest acc : ', accuracy_score(y_test, pred)) # 0.6076388888888888\n",
    "\n",
    "# 교차 검증\n",
    "from sklearn import model_selection\n",
    "cross_vali = model_selection.cross_val_score(model, df.iloc[:,0:2], df.iloc[:,3], cv = 5)\n",
    "print(cross_vali)\n",
    "print(np.round(np.mean(cross_vali), 3)) # 0.639"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb636df8",
   "metadata": {},
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "f3990679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '0' '0']\n",
      "실제값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "분류 정확도 :  0.4388888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.17      0.27       882\n",
      "           1       0.40      0.87      0.54       558\n",
      "\n",
      "    accuracy                           0.44      1440\n",
      "   macro avg       0.53      0.52      0.41      1440\n",
      "weighted avg       0.56      0.44      0.38      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "# SVM model\n",
    "model = svm.SVC(C=1.0).fit(x_train, y_train)\n",
    "# model = svm.LinearSVC(C=1.0, random_state=0).fit(data_train, label_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "print('예측값 : ', pred[:10])\n",
    "print('실제값 : ', np.array(y_test[:10]))\n",
    "\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pred)\n",
    "cl_report = metrics.classification_report(y_test, pred)\n",
    "print('분류 정확도 : ', ac_score) # 0.4388888888888889\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f2c15",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "a7280fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "실제값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "LogisticRegression acc :  0.3875\n",
      "LogisticRegression acc :  0.3875\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀분석\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C = 100.0, random_state = 0)\n",
    "fit_model = model.fit(x_train, y_train)\n",
    "pred = fit_model.predict(x_test)\n",
    "print('예측값 : ', pred[:10])\n",
    "print('실제값 : ', np.array(y_test[:10]))\n",
    "\n",
    "# 분류 정확도\n",
    "print('LogisticRegression acc : ', sum(y_test == pred) / len(y_test)) # 0.3875\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('LogisticRegression acc : ', accuracy_score(y_test, pred)) # 0.3875"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bab26",
   "metadata": {},
   "source": [
    "## ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "5d58a8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "실제값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "ann acc :  0.3875\n",
      "ann acc :  0.3875\n"
     ]
    }
   ],
   "source": [
    "# ann\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(max_iter = 10, eta0 = 0.1, random_state = 1)\n",
    "fit_model = model.fit(x_train, y_train)\n",
    "pred = fit_model.predict(x_test)\n",
    "print('예측값 : ', pred[:10])\n",
    "print('실제값 : ', np.array(y_test[:10]))\n",
    "\n",
    "# 분류 정확도\n",
    "print('ann acc : ', sum(y_test == pred) / len(y_test)) # 0.3875\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('ann acc : ', accuracy_score(y_test, pred)) # 0.3875"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac218cb",
   "metadata": {},
   "source": [
    "## mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "dfdbf41d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '0' '0']\n",
      "실제값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "mlp acc :  0.4479166666666667\n",
      "mlp acc :  0.4479166666666667\n"
     ]
    }
   ],
   "source": [
    "# mlp\n",
    "\n",
    "from sklearn.neural_network._multilayer_perceptron import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter = 1000,\\\n",
    "                    learning_rate_init = 0.01, verbose = 0)\n",
    "fit_model = model.fit(x_train, y_train)\n",
    "pred = fit_model.predict(x_test)\n",
    "print('예측값 : ', pred[:10])\n",
    "print('실제값 : ', np.array(y_test[:10]))\n",
    "\n",
    "# 분류 정확도\n",
    "print('mlp acc : ', sum(y_test == pred) / len(y_test)) # 0.4479166666666667\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('mlp acc : ', accuracy_score(y_test, pred)) # 0.4479166666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9157f149",
   "metadata": {},
   "source": [
    "## 나이브 베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "e49d1ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '0' '0']\n",
      "실제값 :  ['1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "나이브 베이즈 acc :  0.42777777777777776\n",
      "나이브 베이즈 acc :  0.42777777777777776\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "fit_model = model.fit(x_train, y_train)\n",
    "pred = fit_model.predict(x_test)\n",
    "print('예측값 : ', pred[:10])\n",
    "print('실제값 : ', np.array(y_test[:10]))\n",
    "\n",
    "# 분류 정확도\n",
    "print('나이브 베이즈 acc : ', sum(y_test == pred) / len(y_test)) # 0.42777777777777776\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('나이브 베이즈 acc : ', accuracy_score(y_test, pred)) # 0.42777777777777776"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6788d03",
   "metadata": {},
   "source": [
    "## 딥러닝 분류기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b721db4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 180,097\n",
      "Trainable params: 178,113\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "7/7 [==============================] - 1s 23ms/step - loss: 1.0345 - accuracy: 0.5540 - val_loss: 77.3895 - val_accuracy: 0.6011\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6185 - val_loss: 8.0063 - val_accuracy: 0.6011\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.6243 - val_loss: 12.3390 - val_accuracy: 0.6011\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6410 - accuracy: 0.6449 - val_loss: 4.4367 - val_accuracy: 0.3989\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6362 - accuracy: 0.6288 - val_loss: 6.9432 - val_accuracy: 0.3989\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6426 - accuracy: 0.6104 - val_loss: 2.0949 - val_accuracy: 0.3989\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.6256 - val_loss: 2.3527 - val_accuracy: 0.3989\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.5867 - val_loss: 2.9684 - val_accuracy: 0.3989\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6411 - accuracy: 0.6323 - val_loss: 1.0409 - val_accuracy: 0.4275\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.6395 - val_loss: 1.1626 - val_accuracy: 0.5116\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6344 - accuracy: 0.6247 - val_loss: 1.4885 - val_accuracy: 0.4007\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.6126 - val_loss: 6.5279 - val_accuracy: 0.3989\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6379 - accuracy: 0.6314 - val_loss: 2.0153 - val_accuracy: 0.3953\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6344 - accuracy: 0.6171 - val_loss: 4.6534 - val_accuracy: 0.4132\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6240 - accuracy: 0.6301 - val_loss: 4.3009 - val_accuracy: 0.3953\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6360 - accuracy: 0.6252 - val_loss: 2.2246 - val_accuracy: 0.4222\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6280 - accuracy: 0.6216 - val_loss: 5.8219 - val_accuracy: 0.3953\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6144 - accuracy: 0.6292 - val_loss: 1.9842 - val_accuracy: 0.6011\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6370 - accuracy: 0.6265 - val_loss: 0.8186 - val_accuracy: 0.3989\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6318 - accuracy: 0.6229 - val_loss: 4.7225 - val_accuracy: 0.4132\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6136 - accuracy: 0.6180 - val_loss: 2.5079 - val_accuracy: 0.4329\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6109 - accuracy: 0.6176 - val_loss: 2.7565 - val_accuracy: 0.4132\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6162 - accuracy: 0.6086 - val_loss: 3.8001 - val_accuracy: 0.4186\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6292 - accuracy: 0.6350 - val_loss: 7.0600 - val_accuracy: 0.4222\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.6225 - val_loss: 0.9312 - val_accuracy: 0.6064\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.6176 - val_loss: 1.9735 - val_accuracy: 0.4222\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.6193 - val_loss: 1.7441 - val_accuracy: 0.4597\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6115 - accuracy: 0.6296 - val_loss: 2.1766 - val_accuracy: 0.4669\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.6261 - val_loss: 1.0099 - val_accuracy: 0.6047\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.030000000447034835.\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.6261 - val_loss: 1.5678 - val_accuracy: 0.4651\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.6288 - val_loss: 1.7881 - val_accuracy: 0.4812\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.6220 - val_loss: 1.3412 - val_accuracy: 0.4955\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6017 - accuracy: 0.6449 - val_loss: 1.2814 - val_accuracy: 0.4973\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.6382 - val_loss: 1.2255 - val_accuracy: 0.5349\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.6377 - val_loss: 0.9693 - val_accuracy: 0.5474\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6014 - accuracy: 0.6377 - val_loss: 0.8875 - val_accuracy: 0.5242\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6099 - accuracy: 0.6337 - val_loss: 0.8958 - val_accuracy: 0.5868\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5957 - accuracy: 0.6391 - val_loss: 0.8315 - val_accuracy: 0.6100\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5929 - accuracy: 0.6301 - val_loss: 0.8198 - val_accuracy: 0.6136\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.009000000357627868.\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5915 - accuracy: 0.6422 - val_loss: 0.7894 - val_accuracy: 0.6100\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6007 - accuracy: 0.6355 - val_loss: 0.7735 - val_accuracy: 0.6064\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.6364 - val_loss: 0.7777 - val_accuracy: 0.6047\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6413 - val_loss: 0.8151 - val_accuracy: 0.6172\n",
      "Epoch 44/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5914 - accuracy: 0.6413 - val_loss: 0.7770 - val_accuracy: 0.6172\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.6426 - val_loss: 0.7911 - val_accuracy: 0.6029\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.6399 - val_loss: 0.7810 - val_accuracy: 0.6136\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.6408 - val_loss: 0.8527 - val_accuracy: 0.6136\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.6341 - val_loss: 0.7721 - val_accuracy: 0.6118\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.6404 - val_loss: 0.8573 - val_accuracy: 0.6064\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.6399 - val_loss: 0.7865 - val_accuracy: 0.6154\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6422 - val_loss: 0.7652 - val_accuracy: 0.6243\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5834 - accuracy: 0.6435 - val_loss: 0.8106 - val_accuracy: 0.6100\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.6368 - val_loss: 0.7347 - val_accuracy: 0.6154\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.6449 - val_loss: 0.7154 - val_accuracy: 0.6118\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.6462 - val_loss: 0.7397 - val_accuracy: 0.6243\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5871 - accuracy: 0.6458 - val_loss: 0.6901 - val_accuracy: 0.6243\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.6404 - val_loss: 0.7133 - val_accuracy: 0.6369\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5960 - accuracy: 0.6382 - val_loss: 0.6784 - val_accuracy: 0.6315\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5932 - accuracy: 0.6359 - val_loss: 0.6588 - val_accuracy: 0.6279\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5951 - accuracy: 0.6364 - val_loss: 0.6840 - val_accuracy: 0.6404\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5883 - accuracy: 0.6391 - val_loss: 0.6958 - val_accuracy: 0.6315\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6435 - val_loss: 0.6463 - val_accuracy: 0.6261\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5914 - accuracy: 0.6417 - val_loss: 0.6576 - val_accuracy: 0.6369\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.6382 - val_loss: 0.6389 - val_accuracy: 0.6297\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5844 - accuracy: 0.6422 - val_loss: 0.6330 - val_accuracy: 0.6315\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.6471 - val_loss: 0.6289 - val_accuracy: 0.6351\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5942 - accuracy: 0.6359 - val_loss: 0.6242 - val_accuracy: 0.6190\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.6417 - val_loss: 0.6408 - val_accuracy: 0.6351\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5895 - accuracy: 0.6368 - val_loss: 0.6401 - val_accuracy: 0.6315\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5909 - accuracy: 0.6413 - val_loss: 0.6488 - val_accuracy: 0.6243\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6026 - accuracy: 0.6476 - val_loss: 0.6333 - val_accuracy: 0.6315\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.6386 - val_loss: 0.6361 - val_accuracy: 0.6386\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5923 - accuracy: 0.6382 - val_loss: 0.6235 - val_accuracy: 0.6279\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5848 - accuracy: 0.6444 - val_loss: 0.6442 - val_accuracy: 0.6333\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5900 - accuracy: 0.6462 - val_loss: 0.6240 - val_accuracy: 0.6208\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5953 - accuracy: 0.6350 - val_loss: 0.6282 - val_accuracy: 0.6422\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.6382 - val_loss: 0.6477 - val_accuracy: 0.6369\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5925 - accuracy: 0.6422 - val_loss: 0.6143 - val_accuracy: 0.6315\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.6377 - val_loss: 0.6118 - val_accuracy: 0.6297\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.6408 - val_loss: 0.6057 - val_accuracy: 0.6315\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5818 - accuracy: 0.6449 - val_loss: 0.6193 - val_accuracy: 0.6440\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.6489 - val_loss: 0.6052 - val_accuracy: 0.6190\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5895 - accuracy: 0.6377 - val_loss: 0.6178 - val_accuracy: 0.6440\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6494 - val_loss: 0.6176 - val_accuracy: 0.6351\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5936 - accuracy: 0.6328 - val_loss: 0.6080 - val_accuracy: 0.6279\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.6350 - val_loss: 0.6094 - val_accuracy: 0.6440\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.6431 - val_loss: 0.6044 - val_accuracy: 0.6351\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.6368 - val_loss: 0.6133 - val_accuracy: 0.6458\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.6458 - val_loss: 0.6102 - val_accuracy: 0.6154\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.6422 - val_loss: 0.6091 - val_accuracy: 0.6315\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5994 - accuracy: 0.6386 - val_loss: 0.6223 - val_accuracy: 0.6172\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6377 - val_loss: 0.6060 - val_accuracy: 0.6190\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.6489 - val_loss: 0.6149 - val_accuracy: 0.6351\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.6435 - val_loss: 0.6094 - val_accuracy: 0.6333\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.6341 - val_loss: 0.6081 - val_accuracy: 0.6225\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5929 - accuracy: 0.6444 - val_loss: 0.6321 - val_accuracy: 0.6369\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.6440 - val_loss: 0.6108 - val_accuracy: 0.6172\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.002700000163167715.\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.6440 - val_loss: 0.6135 - val_accuracy: 0.6208\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.6511 - val_loss: 0.6114 - val_accuracy: 0.6172\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.6467 - val_loss: 0.6077 - val_accuracy: 0.6154\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.6494 - val_loss: 0.6057 - val_accuracy: 0.6208\n",
      "Epoch 102/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5811 - accuracy: 0.6462 - val_loss: 0.6099 - val_accuracy: 0.6172\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6422 - val_loss: 0.6084 - val_accuracy: 0.6225\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.6471 - val_loss: 0.6056 - val_accuracy: 0.6261\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5807 - accuracy: 0.6431 - val_loss: 0.6038 - val_accuracy: 0.6297\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5778 - accuracy: 0.6489 - val_loss: 0.6043 - val_accuracy: 0.6261\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5796 - accuracy: 0.6485 - val_loss: 0.6037 - val_accuracy: 0.6261\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.6498 - val_loss: 0.6069 - val_accuracy: 0.6208\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.6462 - val_loss: 0.6066 - val_accuracy: 0.6208\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5787 - accuracy: 0.6538 - val_loss: 0.6048 - val_accuracy: 0.6279\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.6350 - val_loss: 0.6039 - val_accuracy: 0.6261\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5900 - accuracy: 0.6502 - val_loss: 0.6036 - val_accuracy: 0.6190\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5832 - accuracy: 0.6525 - val_loss: 0.6025 - val_accuracy: 0.6172\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5857 - accuracy: 0.6462 - val_loss: 0.6027 - val_accuracy: 0.6243\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5958 - accuracy: 0.6502 - val_loss: 0.6035 - val_accuracy: 0.6225\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.6480 - val_loss: 0.6035 - val_accuracy: 0.6190\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.6404 - val_loss: 0.6030 - val_accuracy: 0.6154\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.6502 - val_loss: 0.6021 - val_accuracy: 0.6208\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6588 - val_loss: 0.6034 - val_accuracy: 0.6190\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.6511 - val_loss: 0.6034 - val_accuracy: 0.6279\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.6404 - val_loss: 0.6045 - val_accuracy: 0.6208\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.6502 - val_loss: 0.6040 - val_accuracy: 0.6225\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5852 - accuracy: 0.6440 - val_loss: 0.6036 - val_accuracy: 0.6172\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6516 - val_loss: 0.6052 - val_accuracy: 0.6208\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.6516 - val_loss: 0.6025 - val_accuracy: 0.6172\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.6525 - val_loss: 0.6064 - val_accuracy: 0.6225\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5815 - accuracy: 0.6458 - val_loss: 0.6042 - val_accuracy: 0.6172\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6029 - accuracy: 0.6399 - val_loss: 0.6147 - val_accuracy: 0.6243\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0008100000210106373.\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6012 - accuracy: 0.6489 - val_loss: 0.6112 - val_accuracy: 0.6243\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5833 - accuracy: 0.6574 - val_loss: 0.6094 - val_accuracy: 0.6225\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5817 - accuracy: 0.6480 - val_loss: 0.6074 - val_accuracy: 0.6190\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5856 - accuracy: 0.6520 - val_loss: 0.6059 - val_accuracy: 0.6100\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5811 - accuracy: 0.6458 - val_loss: 0.6041 - val_accuracy: 0.6154\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5783 - accuracy: 0.6485 - val_loss: 0.6030 - val_accuracy: 0.6136\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5824 - accuracy: 0.6547 - val_loss: 0.6031 - val_accuracy: 0.6154\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.6431 - val_loss: 0.6019 - val_accuracy: 0.6136\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.6565 - val_loss: 0.6008 - val_accuracy: 0.6082\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5897 - accuracy: 0.6511 - val_loss: 0.6013 - val_accuracy: 0.6154\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5933 - accuracy: 0.6453 - val_loss: 0.6010 - val_accuracy: 0.6136\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.6408 - val_loss: 0.6006 - val_accuracy: 0.6118\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.6502 - val_loss: 0.6008 - val_accuracy: 0.6172\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5811 - accuracy: 0.6444 - val_loss: 0.6009 - val_accuracy: 0.6154\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6547 - val_loss: 0.6005 - val_accuracy: 0.6172\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.6525 - val_loss: 0.5994 - val_accuracy: 0.6136\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.6494 - val_loss: 0.5995 - val_accuracy: 0.6100\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.6476 - val_loss: 0.5999 - val_accuracy: 0.6154\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.6511 - val_loss: 0.5995 - val_accuracy: 0.6154\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6516 - val_loss: 0.6005 - val_accuracy: 0.6154\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5816 - accuracy: 0.6597 - val_loss: 0.5999 - val_accuracy: 0.6136\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5850 - accuracy: 0.6440 - val_loss: 0.5997 - val_accuracy: 0.6118\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.6547 - val_loss: 0.5995 - val_accuracy: 0.6136\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5787 - accuracy: 0.6534 - val_loss: 0.5998 - val_accuracy: 0.6172\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5787 - accuracy: 0.6471 - val_loss: 0.5998 - val_accuracy: 0.6172\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 0.00024299999931827186.\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5816 - accuracy: 0.6485 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6502 - val_loss: 0.5999 - val_accuracy: 0.6118\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.6494 - val_loss: 0.5998 - val_accuracy: 0.6136\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.6431 - val_loss: 0.5997 - val_accuracy: 0.6118\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.6476 - val_loss: 0.5996 - val_accuracy: 0.6136\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.6471 - val_loss: 0.5996 - val_accuracy: 0.6100\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5804 - accuracy: 0.6498 - val_loss: 0.5996 - val_accuracy: 0.6136\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5874 - accuracy: 0.6511 - val_loss: 0.5996 - val_accuracy: 0.6118\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5880 - accuracy: 0.6507 - val_loss: 0.5996 - val_accuracy: 0.6118\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 7.290000066859647e-05.\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5709 - accuracy: 0.6552 - val_loss: 0.5996 - val_accuracy: 0.6118\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5821 - accuracy: 0.6525 - val_loss: 0.5996 - val_accuracy: 0.6118\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.6556 - val_loss: 0.5996 - val_accuracy: 0.6118\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5724 - accuracy: 0.6538 - val_loss: 0.5996 - val_accuracy: 0.6118\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.6502 - val_loss: 0.5997 - val_accuracy: 0.6100\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.6449 - val_loss: 0.5997 - val_accuracy: 0.6100\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6556 - val_loss: 0.5997 - val_accuracy: 0.6100\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.6489 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5755 - accuracy: 0.6574 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.6511 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 2.18700006371364e-05.\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5804 - accuracy: 0.6525 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5844 - accuracy: 0.6498 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5812 - accuracy: 0.6520 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.6476 - val_loss: 0.5998 - val_accuracy: 0.6118\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.6516 - val_loss: 0.5998 - val_accuracy: 0.6100\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5859 - accuracy: 0.6502 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5778 - accuracy: 0.6480 - val_loss: 0.5998 - val_accuracy: 0.6100\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5843 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5863 - accuracy: 0.6543 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5753 - accuracy: 0.6502 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-06.\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5751 - accuracy: 0.6408 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5781 - accuracy: 0.6507 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.6507 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5855 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.6444 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.968300057342276e-06.\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5733 - accuracy: 0.6574 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.6476 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6052 - accuracy: 0.6399 - val_loss: 0.5999 - val_accuracy: 0.6064\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.6494 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.6498 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5811 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5781 - accuracy: 0.6440 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5727 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5740 - accuracy: 0.6498 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 5.904900035602623e-07.\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6583 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6016 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5784 - accuracy: 0.6507 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5731 - accuracy: 0.6556 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.6391 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.6520 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5779 - accuracy: 0.6480 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.6529 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 1.7714700106807868e-07.\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5889 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6480 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5981 - accuracy: 0.6561 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.6480 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5737 - accuracy: 0.6574 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.6516 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5803 - accuracy: 0.6498 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.6561 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5739 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 5.3144100320423605e-08.\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.6440 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.6431 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.6516 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5779 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5829 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5792 - accuracy: 0.6502 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.594322966980144e-08.\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.6494 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.6543 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5911 - accuracy: 0.6453 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.6462 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5823 - accuracy: 0.6444 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.6498 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5848 - accuracy: 0.6467 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5752 - accuracy: 0.6453 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5855 - accuracy: 0.6467 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 4.782968687777611e-09.\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5809 - accuracy: 0.6435 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5738 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.6453 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.6520 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5739 - accuracy: 0.6498 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5848 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.6592 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5818 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5789 - accuracy: 0.6489 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 1.4348906063332833e-09.\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5766 - accuracy: 0.6556 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.6543 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.6543 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5822 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5758 - accuracy: 0.6507 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5849 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5935 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5739 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 4.304671952226613e-10.\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5785 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5844 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5804 - accuracy: 0.6498 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5792 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.6543 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.6440 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6440 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.6440 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5844 - accuracy: 0.6453 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 1.2914015690146385e-10.\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5880 - accuracy: 0.6395 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.6494 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5812 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.6494 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5942 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.6516 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.6574 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 3.874204707043915e-11.\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6118\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.6417 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5784 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5761 - accuracy: 0.6561 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.6538 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5883 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.6431 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00294: ReduceLROnPlateau reducing learning rate to 1.1622614329298564e-11.\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5778 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5777 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5880 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5734 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5815 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5824 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.6552 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5764 - accuracy: 0.6552 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5702 - accuracy: 0.6538 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 3.486784298789569e-12.\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5794 - accuracy: 0.6556 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5812 - accuracy: 0.6547 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5772 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 1.0460352636160187e-12.\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5784 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.6435 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5785 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.6453 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6588 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5819 - accuracy: 0.6467 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 324/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5854 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 3.1381056607437953e-13.\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.6480 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.6507 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5805 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.6453 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.6435 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6449 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5741 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.6552 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.6543 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.6467 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 9.414316656970733e-14.\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5773 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5779 - accuracy: 0.6601 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5785 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5828 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5887 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5797 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.6507 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 2.8242949564336385e-14.\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.6417 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5803 - accuracy: 0.6431 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6118\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5746 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.6498 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.6511 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.6556 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.6561 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00354: ReduceLROnPlateau reducing learning rate to 8.47288497094487e-15.\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.6494 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5837 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6552 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.6592 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6471 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6529 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5842 - accuracy: 0.6583 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.6471 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.6426 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 2.541865491283461e-15.\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5805 - accuracy: 0.6543 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5710 - accuracy: 0.6494 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5822 - accuracy: 0.6471 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.6467 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.6516 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.6592 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6534 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6440 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 7.625596219740498e-16.\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.6476 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5802 - accuracy: 0.6502 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.6395 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5871 - accuracy: 0.6507 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.6485 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5810 - accuracy: 0.6431 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.6516 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 2.2876788659221496e-16.\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.6516 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.6556 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5801 - accuracy: 0.6597 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6565 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.6543 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5853 - accuracy: 0.6489 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6444 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 6.863036280129093e-17.\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5951 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.6422 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.6601 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5928 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6489 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5800 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5788 - accuracy: 0.6588 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 2.0589108443340587e-17.\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.6417 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.6494 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6494 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5789 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.6556 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6422 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5834 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.6529 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 6.176732334478829e-18.\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.6502 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.6422 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5945 - accuracy: 0.6449 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6529 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6489 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5801 - accuracy: 0.6547 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.6417 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5800 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5756 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00424: ReduceLROnPlateau reducing learning rate to 1.8530196507128117e-18.\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5863 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5752 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5824 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.6444 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5895 - accuracy: 0.6444 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00434: ReduceLROnPlateau reducing learning rate to 5.559058828061344e-19.\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.6489 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5724 - accuracy: 0.6538 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5819 - accuracy: 0.6494 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.6543 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6449 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.6529 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5848 - accuracy: 0.6458 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.6498 - val_loss: 0.5999 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00444: ReduceLROnPlateau reducing learning rate to 1.667717710456949e-19.\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5952 - accuracy: 0.6440 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5765 - accuracy: 0.6444 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5778 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5773 - accuracy: 0.6597 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5748 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.6471 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5798 - accuracy: 0.6529 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.6502 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5730 - accuracy: 0.6579 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00454: ReduceLROnPlateau reducing learning rate to 5.0031532089190294e-20.\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5696 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5957 - accuracy: 0.6444 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5773 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5802 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.6520 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5806 - accuracy: 0.6534 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.6570 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5842 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.6583 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.6458 - val_loss: 0.6000 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00464: ReduceLROnPlateau reducing learning rate to 1.5009459432886634e-20.\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5826 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.6471 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.6435 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5801 - accuracy: 0.6489 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.6561 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5779 - accuracy: 0.6552 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6525 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.6489 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.6480 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.6520 - val_loss: 0.5999 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00474: ReduceLROnPlateau reducing learning rate to 4.502837635995534e-21.\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.6534 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6534 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5792 - accuracy: 0.6547 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.6543 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.6547 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.6458 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5777 - accuracy: 0.6520 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5794 - accuracy: 0.6462 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.6516 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00484: ReduceLROnPlateau reducing learning rate to 1.35085129079866e-21.\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.6552 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6485 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.6525 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.6440 - val_loss: 0.6000 - val_accuracy: 0.6082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.6422 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.6507 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.6507 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5766 - accuracy: 0.6467 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.6391 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6529 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "Epoch 00494: ReduceLROnPlateau reducing learning rate to 4.052553811811463e-22.\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.6444 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.6467 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5823 - accuracy: 0.6511 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6422 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.6476 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.6368 - val_loss: 0.6000 - val_accuracy: 0.6082\n",
      "\n",
      "\n",
      "\"validation loss, accuracy\"\n",
      "18/18 [==============================] - 0s 647us/step - loss: 0.6000 - accuracy: 0.6082\n",
      "\n",
      "\n",
      "\"test loss, accuracy\"\n",
      "45/45 [==============================] - 0s 796us/step - loss: 0.7080 - accuracy: 0.5118\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "input_layer = tf.keras.Input(shape=x_train[0].shape)\n",
    "x = tf.keras.layers.Dense(units=512, activation='relu')(input_layer)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(units=256, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "output_layer = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# 옵티마이저는 SGD, RMSprop, Adam 테스트 해봄\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.1),\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "x_train = x_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "x_test = x_test.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "x_val = x_val.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "\n",
    "mcp_cb = ModelCheckpoint(filepath='C:/Users/user/Desktop/abc/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
    "                       save_best_only=True, save_weights_only=True, mode='min', verbose=0)\n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=10, mode='min', verbose=1)\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=500, batch_size=32 * 10, verbose=1, validation_data=(x_val, y_val), callbacks=[rlr_cb])\n",
    "predicted = model.predict(x_val)\n",
    "print('\\n\\n\"validation loss, accuracy\"')\n",
    "model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "print('\\n\\n\"test loss, accuracy\"')\n",
    "model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "vloss = history.history['val_loss']\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "\n",
    "# 시각화\n",
    "epoch_len = np.arange(len(acc))\n",
    "plt.plot(epoch_len, vloss, c = 'red', label = 'val_loss')\n",
    "plt.plot(epoch_len, loss, c = 'blue', label = 'loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epoch_len, acc, c = 'green', label = 'accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984699d",
   "metadata": {},
   "source": [
    "## 정밀도, 재현율, F1스코어, ROC커브, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd6f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.42594484167517876\n",
      "재현율: 0.7473118279569892\n",
      "F1 스코어: 0.5426154847104749\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 분류 문제에서는 확률을 예측 결과로 사용하므로, 0.5를 기준으로 이진 분류를 수행합니다.\n",
    "# 예측 확률이 0.5보다 크면 1로, 작으면 0으로 변환합니다.\n",
    "y_pred_binary = (predicted > 0.5).astype(int)\n",
    "\n",
    "# 정밀도 계산\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "\n",
    "# 재현율 계산\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "\n",
    "print(\"정밀도:\", precision)\n",
    "print(\"재현율:\", recall)\n",
    "print(\"F1 스코어:\", f1)\n",
    "\n",
    "# ravel은 차원축소\n",
    "fpr, tpr, _ = roc_curve(y_test.ravel(), predicted.ravel())\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.3f})'.format(auc(fpr, tpr))) # AUC : 0.627\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='upper left', fontsize='small')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
